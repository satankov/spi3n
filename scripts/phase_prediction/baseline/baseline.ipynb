{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcc9733-c5df-4106-a8bb-4cfc44bc9128",
   "metadata": {},
   "source": [
    "# Model description\n",
    "\n",
    "`Baseline` is a simple phase prediction model.  \n",
    "\n",
    "\n",
    "We solve binary classification task.  \n",
    "We build one model for each lattice size.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3533e67-115a-472a-a0ca-8c5121e5aeae",
   "metadata": {},
   "source": [
    "## Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa600a-9a32-4188-8b7e-9df694c667bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import spi3n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ac3071-0ed8-409e-b8aa-b33f706affd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_samples):\n",
    "    st = time.time()\n",
    "    data = {}\n",
    "    files = [file for file in os.listdir(\n",
    "             path_to_samples) if ('.csv' in file and 'dup' not in file)]\n",
    "    for file in files:\n",
    "        T = float(file[:-4].replace('_','.'))\n",
    "        data[T] = pd.read_csv(f'{path_to_samples}{file}')\n",
    "    logging.info(f\"Done with files in {path_to_samples}. Took {time.time()-st} sec.\")\n",
    "    return data\n",
    "            \n",
    "\n",
    "class ResNet18(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet = spi3n.models.custom_resnet.resnet18(num_classes=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd52c3-fc02-470e-aa7c-23f9138198dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcb258-d4cc-4a30-afb5-2784900a436d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1d2cb9-267b-421b-bf88-fd863a971763",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "Initialise parameters and create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe8b541-a8e8-4df7-ae7f-7c4de61f35df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "#\n",
    "# SET DATA CONSTANTS\n",
    "#\n",
    "# ==================================================================\n",
    "\n",
    "L = 216  # option: 24, 48, 72, 96, 144, 216(243 if BW)\n",
    "SPIN_MODEL = 'ISING'  # option: 'BW'\n",
    "PATH_TO_SAMPLES = f'../../../{SPIN_MODEL}/data/samples_{L}/'\n",
    "N_IMG = 1500\n",
    "tc = 2/(np.log(1+2**0.5)) # Ising, BW critical T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "#\n",
    "# SET TRANSFORMER\n",
    "#\n",
    "# ==================================================================\n",
    "\n",
    "transform = Compose([\n",
    "    spi3n.transform.array2tensor(),  # create torch.tensor from np.array\n",
    "    spi3n.transform.Rotate([1, 2])   # random rotation of image\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "#\n",
    "# SET TRAINING\n",
    "#\n",
    "# ==================================================================\n",
    "\n",
    "experiment = f'L{L}'\n",
    "n_epochs = 50\n",
    "batch_sz = 512\n",
    "train_test_shares = [2/3*0.9, 2/3*0.1, 1/3],  # train+valid -- 2/3, test -- 1/3\n",
    "init_lr = 1.0e-4\n",
    "save_path = f'{SPIN_MODEL}/{experiment}/'\n",
    "n_cpu = 25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "#\n",
    "# INIT\n",
    "#\n",
    "# ==================================================================\n",
    "\n",
    "spi3n.utils.create_dir(save_path)\n",
    "spi3n.utils.create_dir(f\"{save_path}saved_checkpoints/\")\n",
    "spi3n.utils.set_logger(\n",
    "    f'train.log',\n",
    "    f'{save_path}',\n",
    ")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f\"\"\"Start new pipeline. \n",
    "Model: {SPIN_MODEL}. \n",
    "Path: {PATH_TO_SAMPLES}.\n",
    "Experiment: {experiment}.\n",
    "Device: {device}.\n",
    "\"\"\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b32b53-5b8f-43d2-b407-bc0f875ddb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to memory\n",
    "\n",
    "loaded_data = load_data(PATH_TO_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb30cf6-94e0-40ef-a453-e5d424ff3cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e70377-7c1a-4ecb-ad0c-563727a9b67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d861957e-6e69-41b3-90fe-5715bb1a0012",
   "metadata": {},
   "source": [
    "## Prepare training\n",
    "Initialise NN, loss, optimizer, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481be735-82e6-4f44-ae36-ba674ed196a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(), \n",
    "    lr=init_lr\n",
    ")\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = spi3n.pipeline.make_loaders(\n",
    "    n_img=N_IMG,\n",
    "    d_shares=train_test_shares,\n",
    "    bs=batch_sz,\n",
    "    DataSetClass=spi3n.loaders.SimpleSampler,\n",
    "    dataset_params=dict(\n",
    "        data=loaded_data, \n",
    "        transform=transform\n",
    "    ),\n",
    "    n_workers=n_cpu,\n",
    "    random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fe5cf-1075-4205-bf05-3625493490e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ae229-55dd-4e65-b389-ec68d6a77907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf8c09d6-4ef8-49d5-bfce-20b337e63681",
   "metadata": {},
   "source": [
    "## Stage: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24f479-8376-4152-b000-88038021797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []\n",
    "time_arr = []\n",
    "\n",
    "logging.info(f\"start training. \\texp: {experiment}.\")\n",
    "for e in tqdm(range(n_epochs)):\n",
    "    \n",
    "    # Train\n",
    "    st = time.time()\n",
    "    logging.info(f\"ep: \\t{e}\")\n",
    "    net.train()\n",
    "    _train_loss, n_iter = 0.0, 0\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        T, X = data\n",
    "        X = X.to(device).float()\n",
    "        T = T.to(device)\n",
    "        Y = (T>tc)*1\n",
    "\n",
    "        Y_hat = net.forward(X)\n",
    "        loss = loss_fn(Y_hat, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _train_loss += loss.item() * Y.shape[0]\n",
    "        n_iter += Y.shape[0]\n",
    "\n",
    "    time_arr += [time.time() - st]\n",
    "    train_losses += [_train_loss / n_iter]\n",
    "    logging.info(f\"ep:\\t{e}. train loss: \\t{train_losses[-1]}\")\n",
    "\n",
    "    model_params = copy.deepcopy(net.state_dict())\n",
    "    torch.save(model_params, f'{save_path}saved_checkpoints/ep{e}_model')\n",
    "\n",
    "\n",
    "    # Validate\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        _val_loss, n_iter = 0.0, 0\n",
    "        for data in valid_loader:\n",
    "            T, X = data\n",
    "            X = X.to(device).float()\n",
    "            T = T.to(device)\n",
    "            Y = (T>tc)*1\n",
    "\n",
    "            Y_hat = net.forward(X)\n",
    "            _val_loss += loss_fn(Y_hat, Y).item() * Y.shape[0]\n",
    "            n_iter += Y.shape[0]\n",
    "        val_losses += [_val_loss / n_iter]\n",
    "    logging.info(f\"ep:\\t{e}. valid loss: \\t{val_losses[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120086a-6486-49e8-bb48-cfc2af6bd7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf0f7e-21ca-4368-8237-fade6ab12a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0df89a68-70e7-4c0b-bca4-36b8cfe29610",
   "metadata": {},
   "source": [
    "## Stage: Test best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896b151-fcd4-404d-be8e-d766a033a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set best ep, save path\n",
    "\n",
    "best_epoch = np.argmin(val_losses)\n",
    "logging.info(f\"Best epoch: \\t{best_epoch}.\")\n",
    "logging.info(f\"Training time: {np.mean(time_arr)} +- {np.std(time_arr)/len(time_arr)}\")\n",
    "path_pred_test = f\"{save_path}best_epoch_test.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# save training stats\n",
    "\n",
    "pd.DataFrame({\n",
    "    'L': L,\n",
    "    'e': range(n_epochs),\n",
    "    'train_loss': train_losses,\n",
    "    'valid_loss': val_losses,\n",
    "    't': time_arr\n",
    "}).to_csv(f\"{save_path}train_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ad0aa-6461-4c96-82a4-aa2ca504f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best network\n",
    "net.load_state_dict(torch.load(f'{save_path}saved_checkpoints/ep{best_epoch}_model'))\n",
    "\n",
    "\n",
    "# Test\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    mode = 'w'\n",
    "    header=True\n",
    "    for data in test_loader:\n",
    "        T, X = data\n",
    "        X = X.to(device).float()\n",
    "        T = T.to(device)\n",
    "        Y = (T>tc)*1\n",
    "        Y_hat = net.forward(X).softmax(1)\n",
    "        \n",
    "        df_out = pd.DataFrame({\n",
    "            'L': L,\n",
    "            'T': T.data.cpu().numpy().reshape(-1),\n",
    "            'f_proba': Y_hat[:,0].data.cpu().numpy().reshape(-1),\n",
    "            'p_proba': Y_hat[:,1].data.cpu().numpy().reshape(-1),\n",
    "            'true': Y.data.cpu().numpy().reshape(-1),\n",
    "        })\n",
    "        df_out.to_csv(\n",
    "            path_pred_test,\n",
    "            index=False,\n",
    "            header=header,\n",
    "            mode=mode\n",
    "        )\n",
    "        header = False\n",
    "        mode = 'a'\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c9bc8-bb07-41a5-985c-2b42fe5b8633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb630c-36b6-484a-ab21-3b5bd7b97409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "386426b6-f503-47af-a6aa-395acbe46feb",
   "metadata": {},
   "source": [
    "## Stage: Test specific epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9199696-dc5c-4fe6-bb24-29a3faef5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# set best ep, save path\n",
    "epoch = 7\n",
    "path_pred_test = f\"{save_path}epoch{epoch}_test.csv\"\n",
    "\n",
    "\n",
    "# load best network\n",
    "net.load_state_dict(torch.load(f'{save_path}saved_checkpoints/ep{epoch}_model'))\n",
    "\n",
    "\n",
    "# Test\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    mode = 'w'\n",
    "    header=True\n",
    "    for data in test_loader:\n",
    "        T, X = data\n",
    "        X = X.to(device).float()\n",
    "        T = T.to(device)\n",
    "        Y = (T>tc)*1\n",
    "        Y_hat = net.forward(X).softmax(1)\n",
    "        \n",
    "        df_out = pd.DataFrame({\n",
    "            'L': L,\n",
    "            'T': T.data.cpu().numpy().reshape(-1),\n",
    "            'f_proba': Y_hat[:,0].data.cpu().numpy().reshape(-1),\n",
    "            'p_proba': Y_hat[:,1].data.cpu().numpy().reshape(-1),\n",
    "            'true': Y.data.cpu().numpy().reshape(-1),\n",
    "        })\n",
    "        df_out.to_csv(\n",
    "            path_pred_test,\n",
    "            index=False,\n",
    "            header=header,\n",
    "            mode=mode\n",
    "        )\n",
    "        header = False\n",
    "        mode = 'a'\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3381e2c-ad02-45da-9729-6fa9e3131086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62805645-53ae-4e19-ad37-77976ec2956d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spi3n",
   "language": "python",
   "name": "spi3n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
